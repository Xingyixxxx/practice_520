{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    '''\n",
    "    read the training data file from local HD.\n",
    "    :return: training data，labels\n",
    "    '''\n",
    "    with open(\"data/normal.txt\", encoding=\"utf8\") as normal_f, open(\"data/spam.txt\", encoding=\"utf8\") as spam_f:\n",
    "        normal_data = normal_f.readlines()\n",
    "        spam_data = spam_f.readlines()\n",
    "\n",
    "        normal_label = np.ones(len(normal_data)).tolist()\n",
    "        spam_label = np.zeros(len(spam_data)).tolist()\n",
    "\n",
    "        corpus = normal_data + spam_data\n",
    "\n",
    "        labels = normal_label + spam_label\n",
    "\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_datasets(corpus, labels, test_data_proportion=0.3):\n",
    "    '''\n",
    "    :param corpus: training data\n",
    "    :param labels: labels\n",
    "    :param test_data_proportion:proportion of test data in the whole data set \n",
    "    :return: training data, test data, training labels, test labels\n",
    "    '''\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels,\n",
    "                                                        test_size=test_data_proportion, random_state=10)\n",
    "    return train_X, test_X, train_Y, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_extractor(corpus, ngram_range=(1, 1)):\n",
    "    '''\n",
    "    extract features using Bow model.\n",
    "    :return: the vectorizer and the extrated features.\n",
    "    '''\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range,binary=False,tokenizer=jieba.lcut)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus, ngram_range=(1, 1)):\n",
    "    '''\n",
    "    extract features using Tfidf model.\n",
    "    :return: the vectorizer and the extrated features.\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(min_df=1,norm='l2',smooth_idf=False,use_idf=True,ngram_range=ngram_range,tokenizer=jieba.lcut)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(true_labels, predicted_labels):\n",
    "    print('accuracy:', np.round(metrics.accuracy_score(true_labels,predicted_labels),4))\n",
    "    print('precision:', np.round(metrics.precision_score(true_labels,predicted_labels,average='weighted'),4))\n",
    "    print('recall:', np.round(metrics.recall_score(true_labels,predicted_labels,average='weighted'),4))\n",
    "    print('F1:', np.round(metrics.f1_score(true_labels,predicted_labels,average='weighted'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(classifier,train_features,train_labels,test_features,test_labels):\n",
    "    classifier.fit(train_features,train_labels)\n",
    "    predictions=classifier.predict(test_features)\n",
    "    show_metrics(true_labels=test_labels,predicted_labels=predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Function\n",
    "- The test data is in CSV format\n",
    "- Reads the CSV and extracts the Chinese content\n",
    "- Randomly selects 10 samples from the test set\n",
    "- Displays the test samples before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "# 定义处理函数，提取中文内容\n",
    "def extract_chinese(text):\n",
    "    pattern = r'[\\u4e00-\\u9fa5]+'\n",
    "    chinese_only = ''.join(re.findall(pattern, text))\n",
    "    return chinese_only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_test():\n",
    "\n",
    "    # read test data\n",
    "    df_test = pd.read_csv('./data/test.csv')\n",
    "    print(f'test data shape: {df_test.shape}')\n",
    "\n",
    "    # only keep chinese part\n",
    "    df_test['processed_content'] = df_test['content'].apply(extract_chinese)\n",
    "\n",
    "    # randomly select 10 samples\n",
    "    sample_size = 10\n",
    "    if len(df_test) < sample_size:\n",
    "        sample_size = len(df_test)\n",
    "        print(f'\\ndatabase only have {len(df_test)} records, will use all')\n",
    "\n",
    "    sample_indices = random.sample(range(len(df_test)), sample_size)\n",
    "    sample_data = df_test.iloc[sample_indices]\n",
    "\n",
    "    print(f'\\nrandomly selected {sample_size} samples:')\n",
    "    for i, (idx, row) in enumerate(sample_data.iterrows()):\n",
    "        print(f'sample {i+1}:')\n",
    "        print(row['processed_content'])\n",
    "        print('-' * 50)\n",
    "\n",
    "    selected_samples = sample_data['processed_content'].tolist()\n",
    "\n",
    "    return selected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/homework/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/07/3p41fxw138b_lz7hdy4spqjh0000gn/T/jieba.cache\n",
      "Loading model cost 1.010 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classifier with BOW:\n",
      "accuracy: 0.9897\n",
      "precision: 0.9897\n",
      "recall: 0.9897\n",
      "F1: 0.9897\n",
      "Naive Bayes classifier with Tfidf:\n",
      "accuracy: 0.9863\n",
      "precision: 0.9864\n",
      "recall: 0.9863\n",
      "F1: 0.9863\n",
      "test data shape: (12924, 1)\n",
      "\n",
      "randomly selected 10 samples:\n",
      "sample 1:\n",
      "以下不能正确显示请点此\n",
      "--------------------------------------------------\n",
      "sample 2:\n",
      "提你希望得到的工资水平呵呵这方面我也没有经验犯错了仅仅第二天下午我就接到了电话通知面试时间这次换了个声音很好听人也很客气之后的所有事情都是与他联系的可惜最后还是只闻其声未曾谋面面试就在几天后我上网看了看智联招聘的文章其中有很多英语面试问题集锦看的时候没过脑子面试的时候蔡发现怎么这么像啊当时就了没好好准备到了亮马大厦层发现已经有两个在等了着装都很随意其中一个穿短花裙上面好多褶子头发也没有梳理好还穿着很要命的肉色短丝袜\n",
      "--------------------------------------------------\n",
      "sample 3:\n",
      "活动安排香山邮局周六晚三岔口西扎营小游戏睡觉周日自然醒早餐或午餐老望京植物园约下午活动级别费用自己的交通费以及气罐的均摊费用共约元左右食物和饮水早餐午餐周六晚上的小水最少吧背不动了倒掉背上去了洗脸刷牙也不用太省了装备要求帐篷报名时注明个数和大小炉头自备气罐费用头灯登山鞋长衣长裤等最好带登山杖打草惊蛇用一些常见药品请参见其他负重活动的帖子免责声明任何户外活动都存在风险参加者请熟读绿野公约常见问答里面有出了任何事情皆与他人无关秉承绿野自助精神活动中请不要随便帮助他人或轻易请求他人的帮助报名方式跟帖或私信报名可以不留电话但请注明性别帐篷和炉头气罐的情况加注只在扎营地或者在废弃窑洞生火其他时间禁止开火全程禁止吸烟请自带垃圾袋收走不可降解的个人垃圾迟到者自行追赶或单独行动返回参考链接\n",
      "--------------------------------------------------\n",
      "sample 4:\n",
      "邮件系统免费下载终身可用\n",
      "--------------------------------------------------\n",
      "sample 5:\n",
      "免费注册中国商贸网提供企业建站企业发布产品信息免费注册中国商贸网你就可以享受中国商贸网的免费普通注册用户的所有服务务了免费企业建站企业发布供求信息管理供求信息建立企业网站及推广建立企业产品展示厅管理企业产品展示厅建立网络售销联盟创建企业形象网站提供智能化联网办公管理信息查询和联络在线订单和售销产品寻求合作商机发布企业招聘信息查询人才需求信息在线商务销售培训推荐明星企业享受技术支持与答疑现在就进行注册你将获得中国商贸一年高级会员资格注册地址查询商情囊括全省及全国各类的商业信息及相关的商业机会供您查阅发布商情发布您的买卖合作代理等与商贸相关的商业信息每日最新每天多条来自全国范围的最新供求信息助您把握稍纵即逝的商机产品发布发布您公司或个人需要出售的产品及相关产品进行网络销售企业名录免费创建您的公司网页把您的公司网页加入我们的企业名录产品定购按分类展示各种样式的产品进行定购和销售人才市场发布公司招聘信息查询人才需求行业信息介绍广东省以及全国炯眯幸档亩态商务服务介绍企业之间销售管理一体化的市场营销中国商贸网地址广东省阳绞心铰号电话传真\n",
      "--------------------------------------------------\n",
      "sample 6:\n",
      "尊敬的公司经理财务您好我深圳宏易实业有限公司公司在全国各地大城市设有分公司因进项较多完成不了每月销售额度现我公司有剩余的发票可以低点向贵公司代开供贵公司财务做帐及抵扣可以验证后付款代开项目如下国税普通商品销售发票地税广告运输建筑安装及其他服务行业发票增值税增值税发票及海关缴款书简称海关完税凭证如有需要请来电咨询联系人王先生电话手机\n",
      "--------------------------------------------------\n",
      "sample 7:\n",
      "分手吧我觉得有钱没钱并不重要但是从小养成的消费观念很重要男人读研甚至工作以后如果还是不知道在该花钱的地方适当花钱该修饰的地方适当修饰是很让人头疼的一件事不是说每个人都要多么小资但是年纪大了尤其是工作以后需要接触很多人如果不修边幅会给人留下不太好的印象也会因此而错失很多机会我觉得你的就是太放不开了而这些行为举止都跟从小周围环境的影响有关长到这么大已经很难改变了我们相识在水木版上还是在去年夏末的时候我因为工作等各种问题太过郁闷心情跌到底谷在版上征聊遇到了他当天没怎么聊接下来将近个月的时间我们聊的特别好我最强烈的感受是我们在诸多问题上看法都比较相似都比较成熟客观心态都比又快中秋了也就是去年中秋前的几天我的电脑出问题这是我以前单身时一直比较郁闷的问题我的电脑水平属于菜鸟级每次出问题我都很无助很自然就想到了他让他帮我来修一下就这样我们见面了见面的那天下午他好像刚刚洗完衣服没有衣服换了穿着一件他帮我修电脑我请他吃饭吃饭的时候他一直盯着我看他后来说他对我是一见钟情他喜欢胖胖的可爱的女孩子我当时从他的眼神中看到了这个男孩儿的刚毅我认定他虽然身村瘦小但是会是一个很有责任心和男人味的人\n",
      "--------------------------------------------------\n",
      "sample 8:\n",
      "首页人才信息招聘信息兼职专区校园招聘新闻中心培训信息猎头专区免费注册参加野外拓展训练好运等着您免费注册成为会员填写完整简历就有机会免费参加野外拓展训练活动二天一夜的激情之旅演练您的团队协作能力挖掘发挥您的潜能为您在今年后的职场上拓展更宽广的一片天地活动时间年月至年月日活动内容凡在指定活动时间内免费注册成为会员并填写完整简历的用户就有机会报名免费参加更有众多奖品等你拿活动主题挑战自我引领团队中企拓展训练营拓展您的舞台助您摘取职场桂冠奖项设置团队优胜奖每人可获奖金元奖项设置最佳团队领导者可获奖金元奖项设置纪念品参加方法免费注册成为本站会员并填写完整简历奖项设置在线进行报名参加奖项设置奖项设置在线公布中奖免费活动人员名单活动声明本活动全部解释权归本公司所有拓展活动日程及活动安排第一天指定地点集合出发空调大巴全程陪同到达拓展基地宾馆三星级标准宾馆午餐到达基地热身夺宝奇兵定向越野拓展运动夏客努巴手推车穿越神网罐头鞋穿越峡谷彩弹射击与同伴一起体验野战的乐趣宾馆晚餐或草坪露天烧烤篝火晚会及搞笑游戏活动轻松一下下返回宾馆自由活动第二天起床洗漱宾馆自助早餐离开宾馆向基地出发徒步穿越大型拓展运动信任背摔空中抓杆缅甸桥蜘蛛网基地餐厅午餐皮艇竞技或水上缅甸桥极限攀岩活动结束评选优胜团队颁奖起程回上海具体活动内容以活动当日内容为准关于我们法律声明服务介绍收费标准商务合作招聘上海招聘招聘信息求职上海求职求职信息猎头服务人事外包人事培训人才评测定向委培人才派遣中国企业招聘网助您摘取职场桂冠\n",
      "--------------------------------------------------\n",
      "sample 9:\n",
      "您好我公司有多余的发票可以向外代开国税地税运输广告海关缴款书如果贵公司厂有需要请来电洽谈咨询联系电话陈先生谢谢顺祝商祺\n",
      "--------------------------------------------------\n",
      "sample 10:\n",
      "广州新誉服饰烫图工艺厂是一家经营专业服装烫图各种八角平片压克力烫片烫石平石半圆桃心二涧三角四角彩等产品的公司本公司拥有先进的生产加工设备产品厂家直销欢迎广大客户来板来样定做公司本着质量可靠交货及时价格合理的经营宗旨我们想之客户所想力求同客户建立长期的互利互惠的合作关系客户的要求就是我们的目标能为客户提供优质的产品和满意的服务是我们最大的愿望与客户共同成功是我们不变的追求祝顺商祺联系人詹溢宗联系电话电话传真\n",
      "--------------------------------------------------\n",
      "bow input predictions:  [0. 1. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "tfidf input predictions:  [0. 1. 1. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #prepare trainging data set\n",
    "    corpus,labels=read_file()\n",
    "    train_X, test_X, train_Y, test_Y=divide_datasets(corpus,labels)\n",
    "    \n",
    "    #blank1\n",
    "    #convert training data into vectors in Bow\n",
    "    bow_vectorizer, bow_train_features = bow_extractor(train_X)\n",
    "    bow_test_features = bow_vectorizer.transform(test_X)\n",
    "    \n",
    "    #blank2\n",
    "    #convert training data into vectors in Tfidf\n",
    "    tfidf_vectorizer, tfidf_train_features = tfidf_extractor(train_X)\n",
    "    tfidf_test_features = tfidf_vectorizer.transform(test_X)\n",
    "    \n",
    "    #construct the Naive Bayes classifier objectc for Bow and Tfidf\n",
    "    mnb_bow = MultinomialNB()\n",
    "    mnb_tfidf = MultinomialNB()\n",
    "    \n",
    "    #train the Bow model and evaluate it\n",
    "    print(\"Naive Bayes classifier with BOW:\")\n",
    "    mnb_bow_predictions = evaluate_model(classifier=mnb_bow,\n",
    "                                                       train_features=bow_train_features,\n",
    "                                                       train_labels=train_Y,\n",
    "                                                       test_features=bow_test_features,\n",
    "                                                       test_labels=test_Y)\n",
    "    \n",
    "    #train the Tfidf model and evaluate it\n",
    "    print(\"Naive Bayes classifier with Tfidf:\")\n",
    "    mnb_tfidf_predictions = evaluate_model(classifier=mnb_tfidf,\n",
    "                                                       train_features=tfidf_train_features,\n",
    "                                                       train_labels=train_Y,\n",
    "                                                       test_features=tfidf_test_features,\n",
    "                                                       test_labels=test_Y)\n",
    "\n",
    "    #blank3\n",
    "    #enter some new data to feel the accuracy of the program\n",
    "    input = final_test()\n",
    "    \n",
    "    bow_input_features = bow_vectorizer.transform(input)\n",
    "    tfidf_input_features = tfidf_vectorizer.transform(input)\n",
    "    print('bow input predictions: ',mnb_bow.predict(bow_input_features))\n",
    "    print('tfidf input predictions: ',mnb_tfidf.predict(tfidf_input_features))\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
